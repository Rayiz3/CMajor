---
title: '[CM301] 02. 알고리즘의 분석'
description: ''
author: Doun
date: 2025-10-16 14:00:00 +0900
categories: [CM301. 알고리즘]
tags: [알고리즘]
pin: true
math: true
mermaid: true
image:
  path: /assets/img/thumbnails/cm301/2.png
  lqip: data:image/webp;base64,UklGRpoAAABXRUJQVlA4WAoAAAAQAAAADwAABwAAQUxQSDIAAAARL0AmbZurmr57yyIiqE8oiG0bejIYEQTgqiDA9vqnsUSI6H+oAERp2HZ65qP/VIAWAFZQOCBCAAAA8AEAnQEqEAAIAAVAfCWkAALp8sF8rgRgAP7o9FDvMCkMde9PK7euH5M1m6VWoDXf2FkP3BqV0ZYbO6NA/VFIAAAA
  alt: '[CM301] 02. 알고리즘의 분석'
---

## 목표 세우기 - 올바른 알고리즘

### 정당성 (Correctness)

 &ensp;여러분은 어떤 문제를 풀기 위해 여러분만의 알고리즘을 만들었습니다. 과연 이 알고리즘은 제대로 굴러가는 걸까요? 여러분이 알고리즘을 알맞게 만들었는지 확인하려면, 아래 두 조건을 만족하는지 확인해야 합니다.

1. 모든 입력값(instance)에 대해서 올바른 결과값을 내놓아야 하며

2. 제 시간 안에 끝나야 한다.

 &ensp;만약 이를 모두 만족한다면 그 알고리즘은 **정당하다(Correct)**고 할 수 있습니다.

<img src="{{ 'assets/img/illustration/cm301/2_1.png' | absolute_url }}" alt="image1" class="post" />

### 루프 (Loop)

 &ensp;앞으로 수많은 예시들을 살펴보며 알게되겠지만, 알고리즘에서 지루하고 똑같은 일을 처리하는 데에는 **반복문(iteration)**만큼 좋은 것이 없습니다. 반복문이 계속 돌면서 실행되는 구간을 **루프(Loop)**라고 하고, 꼭 알고리즘 공부가 아니더라도 코드에서 이 루프를 굉장히 자주 보게 될 거에요.<br>

 &ensp;루프는 단순히 똑같은 작업을 반복할 수도 있지만, 반복마다 특정 조건이나 값이 달라지기도 합니다. 반면 반복마다 똑같이 유지되는 조건도 있을거에요. 루프 안에서 항상 참인 조건을 **루프 불변량(Loop invariants)**라고 합니다. 이 불변량은 알고리즘이 왜 정당한지 증명하는데 도움이 될 수 있는 중요한 요소입니다.<br>

 &ensp;루프불변량은 크게 **루프의 처음시점, 진행중, 그리고 종료시점** 이 세가지 부분에서 참임을 보여야 성립합니다.

| 단계                  | 시점                    |
| :-------             | :-------                |
| 처음 (Initialization) | 루프가 처음 시작되기 전    |
| 중간 (Maintenance)    | 루프의 한 반복이 끝났을 때 |
| 끝 (Termination)      | 루프가 끝날 때           |

```python
sum = 0
i = 1
while i <= n:
    sum += i
    i += 1
```

<img src="{{ 'assets/img/illustration/cm301/2_2.png' | absolute_url }}" alt="image2" class="post" />

## 알고리즘 분석하기

 &ensp;어떻게 해서 여러분은 방금 만들어낸 코드가 잘 작동하여 논리적 결함 없이 정당하다는 것을 증명해내었습니다. 이거면 충분할까요?

<img src="{{ 'assets/img/illustration/cm301/2_3.png' | absolute_url }}" alt="image3" class="post" />

 &ensp;여유가 있다면, 우리는 이 알고리즘이 **좋은** 알고리즘인지도 따져볼 수 있겠습니다. 일반적으로 알고리즘이 좋고 나쁜지는, 알고리즘이 종료될 때 까지 걸리는 **실행시간(Running time)**을 기준으로 판단하게 됩니다.

### 점근적 해석(Asymptotic analysis)

<img src="{{ 'assets/img/illustration/cm301/2_4.png' | absolute_url }}" alt="image4" class="post" />

 &ensp;맞아요! 실제로 알고리즘의 실행 시간을 측정하는 행위는 프로그램이 실행되는 컴퓨터 환경에 따라 달라질 수 밖에 없습니다. 때문에 우리는 컴퓨터 환경에 대한 영향을 완전히 배제하고, **순수히 알고리즘 상으로 걸리는 이론적 시간만을 고려**할겁니다. 입력값을 아-주 크게 넣어줌으로서 해결할 수 있는데, 입력이 커질수록 컴퓨터 환경에 의한 차이보다 알고리즘 상의 차이가 실행시간에 영향을 더 많이 주게 되거든요. 입력값이 무한에 가까워졌을 때를 고려한다고 하여 이를 **점근적 해석(Asymptotic analysis)**이라고 합니다.

<img src="{{ 'assets/img/illustration/cm301/2_5.png' | absolute_url }}" alt="image5" class="post" />

 &ensp;점근적 해석에는 또 다른 특징이 있는데, 실행시간을 **가장 간단한 형태의 수식으로 나타낸다**는 것입니다. 이것도 입력값이 무한에 가깝다는 가정으로부터 나오는데, 수식들을 입력값 크기에 대한 실행시간의 그래프로 그렸을 때 생기는 **미세한 차이가 모두 무시될 수 있기 때문**입니다. 예를 들어 입력 크기가 $n$일 때 실행시간이 $2n^2 + n$인 알고리즘과 $n^2$인 알고리즘이 있다고 해봅시다. 수식상으로만 보면 첫 번째 알고리즘이 더 오래 걸립니다. 하지만 n이 무한으로 가면 그것과 상관 없이 두 알고리즘 다 적당한 포물선의 형태만 보이게 될 거에요. 그래서 우리는 **자잘한 항들은 다 버리고 최고차항인 $n^2$만 남겨버립니다**.

<img src="{{ 'assets/img/illustration/cm301/2_6.png' | absolute_url }}" alt="image6" class="post" />

### 표기법 (Notation)

 &ensp;모든 알고리즘이 항상 같은 시간동안 실행되지는 않습니다. 입력값이 어떤지에 따라 실행시간이 짧을 수도, 혹은 길 수도 있죠. 그렇기 때문에 우리는 생각할 수 있는 **가장 최악의 경우를 생각**하게 됩니다. 최악의 수를 지표로 한다면 적어도 상상했던 것 보다 더 나쁜 일이 일어나지는 않을테니까요.
 
<img src="{{ 'assets/img/illustration/cm301/2_7.png' | absolute_url }}" alt="image7" class="post" />

 &ensp;수식으로 표기할 때는 대문자 O를(0이 아닙니다!)사용해 $f(n) = O(n)$과 같은 식으로 표기하고, 이를 **Big-O 표기법(BigOh Notation)**이라고 합니다.
 
<img src="{{ 'assets/img/illustration/cm301/2_8.png' | absolute_url }}" alt="image8" class="post" />

 &ensp;참고로, 아래는 Big-O 표기법 외에도 사용할 수 있는 표기법들과 그 정의입니다.

| 표기법                  | 조건                  | 정의 | $\lim_{n\to\infty}f/g$ |
| :------------------    | :------------------- | :------- | :------- |
| Theta ($\Theta$)       | $f(n) \approx cg(n)$ | $\forall \; n \geq n_0 \quad \exists \; c_1, c_2, n_0 > 0 \quad 0 \leq c_1g(n) \leq f(n) \leq c_2g(n)$| $\mathbb{R}^+$ |
| BigOh ($O$)            | $f(n) \leq cg(n)$    | $\forall \; n \geq n_0 \quad \exists \; c, n_0 > 0 \quad 0 \leq f(n) \leq cg(n)$ | $\mathbb{R}^+ \; or \; 0$ |
| Omega ($\Omega$)       | $f(n) \geq cg(n)$    | $\forall \; n \geq n_0 \quad \exists \; c, n_0 > 0 \quad 0 \leq cg(n) \leq f(n)$ | $\mathbb{R}^+ \; or \; \infty$ |
| LittleOh ($o$)         | $f(n) < cg(n)$       | $\forall \; n \geq n_0, c > 0 \quad \exists \; c, n_0 > 0 \quad 0 \leq f(n) < cg(n)$| $0$ |
| LittleOmega ($\omega$) | $f(n) > cg(n)$       | $\forall \; n \geq n_0, c > 0 \quad \exists \; c, n_0 > 0 \quad 0 \leq cg(n) < f(n)$| $\infty$ |

[fig8_1]

 &ensp;표에서 보이듯이 가장 정확한 측정 방식은 상한선과 하한선이 모두 명시된 **$\Theta$표기법**입니다. 하지만 실제로는 두 가지 경계를 모두 찾아야 하기 때문에 직접 계산하기에는 조금 번거로운 편입니다.

> **Theorem.**<br> $f(n) = \Theta(g(n)) \; \leftrightarrow \; f(n) = O(g(n)) \; 이고 \; f(n) = \Omega(g(n))$
{: .prompt-theorem }

 &ensp;아래는 표기법들로부터 도출할 수 있는 몇 가지 성질들입니다.

> **Property 1.**<br> $f \in O(g) \; \land \; g \in O(h) \; \rightarrow \; f \in O(h)$  ($\Theta$, $\Omega$, $o$, $\omega$에 대해서도 동일)<br>
**Property 2.**<br> $f \in O(g) \; \leftrightarrow \; g \in \Omega(f), \quad f \in o(g) \; \leftrightarrow \; g \in \omega(f)$<br>
**Property 3.**<br> $f \in \Theta(g) \; \leftrightarrow \; g \in \Theta(f)$<br>
**Property 4.**<br> $\Theta$는 [동치관계(Equivalence relation)][1]이다.<br>
**Property 5.**<br> $O(f+g) = O(max \{ f, g \} ), \quad \Omega(f+g) = \Omega(min \{f , g \} )$
{: .prompt-info }

## 알고리즘 분석이 중요한 이유

 &ensp;솔직히 일상에서 우리가 알고리즘의 속도차이를 체감하는 경우는 많지 않습니다. 하지만 여러분이 듣는 컴퓨터 과학에 대한 고학년 수업에서 과제를 복잡하게 만드는 악취미가 있으신 교수님이 있다면, 그 차이를 느낄 수 있을거에요. 실제 현업에서 다루는 프로그램은 더더욱 그럴테고요. 때문에 알고리즘의 성능을 분석하는 것은 여러가지 측면에서 모두에게 도움이 됩니다.

- 만약 알고리즘이 이상적인 실행시간을 가지고 있다고 판단되면, 이후 다른 프로그램을 작성할 때도 그 알고리즘을 사용할 수 있을겁니다.

- 문제상황이 더 커지면 얼마나 시간이 걸릴지 미리 예측할 수 있습니다.

- 현재의 알고리즘이 이상적이지 않아도 상관 없습니다. 알고리즘을 분석하는 활동 자체가 알고리즘을 개선할 기회를 줄 수도 있습니다.

- 알고리즘의 성능을 분석하면서 그 활동 기작에 대해 더 잘 이해할 수도 있고요.

- 알고리즘이 얼마나 **'어려운지(hard)'** 알 수도 있지만, 이 이야기는 잠시 미뤄둡시다...
 
<img src="{{ 'assets/img/illustration/cm301/2_9.png' | absolute_url }}" alt="image9" class="post" />

[1]: /CMajor/posts/cm201-5/#순서가-없는-관계